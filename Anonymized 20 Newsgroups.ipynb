{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will replicate the textual analysis provided as a sample by scikit-learn using the fully anonymized text data processed through our text-obscuring script. At the conclusion, we will compare the results that could be derived from the obscured text and the original text, walk through the configuration options of the obscuration script, and discuss some of the challenges with working with obscured data.\n",
    "\n",
    "Find the original instructions at: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of minimizing steps, we will load the entire dataset, obscure it all at once, split it later into training and testing sets using scikit learn, instead of loading the presplit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the data in raw form \n",
      "\n",
      "                    target                                               data\n",
      "0                 sci.med  From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
      "1  soc.religion.christian  From: swf@elsegundoca.ncr.com (Stan Friesen)\\n...\n",
      "2  soc.religion.christian  From: David.Bernard@central.sun.com (Dave Bern...\n",
      "3           comp.graphics  From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...\n",
      "4                 sci.med  From: billc@col.hp.com (Bill Claussen)\\nSubjec...\n",
      "5  soc.religion.christian  From: mauaf@csv.warwick.ac.uk (Mr P D Simmons)...\n",
      "6                 sci.med  From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady)\\n...\n",
      "7           comp.graphics  From: dfegan@lescsse.jsc.nasa.gov (Doug Egan)\\...\n",
      "8           comp.graphics  From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JPE...\n",
      "9           comp.graphics  From: chu@TorreyPinesCA.ncr.com (Patrick Chu 3...\n"
     ]
    }
   ],
   "source": [
    "#In order to use the csv obscuring python script, the data must be in CSV format. Exporting it as such:\n",
    "data_df = pd.DataFrame(columns = [\"target\", \"data\"])\n",
    "data_df[\"target\"] = [twenty_train.target_names[i] for i in twenty_train.target]\n",
    "data_df[\"data\"] = twenty_train.data\n",
    "#data_df.to_csv(\"newsgroups.csv\")\n",
    "print(\"A sample of the data in raw form\", \"\\n\\n\", data_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   target                                      obscured_data\n",
      "0                 sci.med  b4Seg 10Khk dRaYm LYwJD ujMnQ S7fhI tVqRr aSvx...\n",
      "1  soc.religion.christian  b4Seg gMgiz v3kDg mwDQ6 fjpY2 H_Vzl BxcvF aSvx...\n",
      "2  soc.religion.christian  b4Seg VXnD4 HGFtW 0VE5D UNsQQ fjpY2 dx0ia HGFt...\n",
      "3           comp.graphics  b4Seg ympNG hnGMJ FhNWX WWr2H fjpY2 oa748 5EKh...\n",
      "4                 sci.med  b4Seg vzC1q -XaO6 7D57- fjpY2 _6ozZ _1RCs aSvx...\n",
      "5  soc.religion.christian  b4Seg nIIie ujOQs qPpKp Q2CIN 35sOC rvND4 Lvw4...\n",
      "6                 sci.med  b4Seg P2WMC jCrYJ cZV5M iT3VW ujMnQ 4v_fB P2WM...\n",
      "7           comp.graphics  b4Seg lGib2 lwttC dulL- BCuBV 1Cnnx tAD8R KVn_...\n",
      "8           comp.graphics  b4Seg -IKdR dRaYm c8m-p ujMnQ 7cmJN MGCyx aSvx...\n",
      "9           comp.graphics  b4Seg GAkWy NHVa6 mwDQ6 fjpY2 4Gs1v GAkWy -dgh...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Importing the data having been cleansed with these configuration options.\n",
    "\n",
    "file_name = newsgroups\n",
    "output_base = data\n",
    "column_name = data\n",
    "delete_column = Yes\n",
    "index_num = 0\n",
    "case_sensitive = No\n",
    "stemming = No\n",
    "remove_punctuation = Yes\n",
    "salt_string = exampleString\n",
    "concat_hashes = 5\n",
    "combine_above = None\n",
    "combine_below = None\n",
    "stop_words = \n",
    "stop_above_words = \n",
    "stop_below_words = \n",
    "'''\n",
    "\n",
    "anon_data = pd.read_csv(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_NoStem_NoPunc_Concat5_AboveNone_BelowNone.csv\")\n",
    "print(anon_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the words have all been converted into numbers, they are stored as space seperated strings so the functions used on words will work on the numbers. \n",
    "\n",
    "The first two lines are spliting the dataset randomly into training and testing. This means that our training and testing sets will differ from the example, but will be split in a statistically sound manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = anon_data[\"obscured_data\"]\n",
    "y = anon_data[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2255x38015 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 395378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vocabulary still contains the locations of the numeralized words. Here '38264' is the number for 'from'\n",
    "count_vect.vocabulary_.get(u'b4Seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training A Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one difficulty in working with the anonymized data. Without the mapping of the original word to its randomized string, one who is building the classification model cannot use meaningful novel data to check the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, for the sake of demonstration, it is possible to test the classifier by finding the equivalent string of numbers to \"God is love\" and \"OpenGL on the GPU is fast\" because we have the mappings exported from the obscuration process. However, we run into another difficulty. By searching the original training data, it is revealed that \"GPU\" only appears in these email addresses: \"C5u5LG.C3G@gpu.utcc.utoronto.ca\" and \"edwest@gpu.utcc.utoronto.ca\" which are turned into seperate words: \"c5u5lg c3g gpu utcc utoronto ca\" and \"edwest gpu utcc utoronto ca\". Then \"gpu\" is converted into the string \"Bb4UV\". So we can see that using the string \"gpu\" is not matching what we would expect it to. However, this insight is only possible with non-obscured data, the lack of which could lead to a flawed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is Love' => 'uYWvU CWUT_ cr2_s' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => 'fGKDi o3qdl Zdr9p Bb4UV CWUT_ HkaPm' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['uYWvU CWUT_ cr2_s', 'fGKDi o3qdl Zdr9p Bb4UV CWUT_ HkaPm']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category, original in zip(docs_new, predicted, [\"God is Love\", \"OpenGL on the GPU is fast\"]):\n",
    "    print('%r => %r => %s' % (original, doc, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The predictions are the same as the uncleansed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894946808511\n"
     ]
    }
   ],
   "source": [
    "# A bit of a simpler, built-in way to get the accuracy score.\n",
    "from sklearn import metrics\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that, using the Naive Bayes, we achieved a similar classification accuracy to their 83.4% with the our obscured strings. Our accuracy is not the exact same for a number of reasons. First, the original walkthrough used predivided training and testing data. We split our set using the scikit learn's function. Also, we made two selections in obscuring our data: to striped punctuation and run as case insensitive.\n",
    "\n",
    "Now we will try the linear support vector machine using their same presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948803191489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='hinge', \n",
    "                                               penalty='l2',\n",
    "                                               alpha=1e-3, \n",
    "                                               random_state=42,\n",
    "                                               max_iter=5, \n",
    "                                               tol=None)),])\n",
    "# Repeated code from above\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, our classification accuracy above and report are quite similar to their 91.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.99      0.91      0.95       339\n",
      "         comp.graphics       0.90      0.99      0.95       386\n",
      "               sci.med       0.98      0.93      0.95       388\n",
      "soc.religion.christian       0.94      0.96      0.95       391\n",
      "\n",
      "           avg / total       0.95      0.95      0.95      1504\n",
      "\n",
      "[[310   3   6  20]\n",
      " [  0 383   1   2]\n",
      " [  0  26 359   3]\n",
      " [  3  12   1 375]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same grid search with our classifier. However, we would expect that some parameters no longer behave similarly. For example, the model builder looses flexibility in using information lower than the word level on which to model the target data, such as letters or groups of punctuation, once the configuration options have been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1,1),(1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train[:400], y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.predict(['16572 24157 31156'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8975\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search has returned the same parameters as with the original data with a very similar accuracy score to their 90.0%.\n",
    "\n",
    "This concludes the example that was provided by scikit learn. Now, we will look at some of the configuration options for the obscuration script and how they effect accuracy and interpretibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring The Obscuration Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As remarked upon above, the obscuration process takes a number of configuration options that can affect the ability of an individual to create a useful model with the obscured text. We will begin by isolating these one at a time to notice how it changes the model. Recall the configuration options in the initial example (not case sensitive, not stemming, removing punctuation, no stop words). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency, we will use these optimized parameters for the SVM model and change the obscuration configurations. Our baseline score is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958239639118\n"
     ]
    }
   ],
   "source": [
    "text_clf2 = Pipeline([('vect', CountVectorizer(ngram_range=(1,1))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                    ('clf', SGDClassifier(loss='hinge', \n",
    "                                               penalty='l2',\n",
    "                                               alpha=.001, \n",
    "                                               random_state=42,\n",
    "                                               max_iter=5, \n",
    "                                               tol=None)),])\n",
    "\n",
    "# Using the optimized parameters, computes a base cross-validated accuracy score for the configurations above.\n",
    "scores = cross_val_score(text_clf2, X, y, cv=5, scoring='accuracy')\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with case sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_get_accuracy(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    X = data[\"obscured_data\"]\n",
    "    y = data[\"target\"]\n",
    "    scores = cross_val_score(text_clf2, X, y, cv=10, scoring='accuracy')\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95744231955807635"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "case_sensitive = Yes \n",
    "'''\n",
    "load_and_get_accuracy(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_Case_NoStem_NoPunc_AboveNone_BelowNone.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for this particular dataset, the accuracy has very slightly decreased. \n",
    "\n",
    "Next, we will reset case sensitivity and using NLTK stemming, which converts multiple forms of the same word into their common root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96089482060959774"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stemming = Yes \n",
    "'''\n",
    "load_and_get_accuracy(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_Stem_NoPunc_AboveNone_BelowNone.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a slight increase in the accuracy score.\n",
    "\n",
    "Next, we will include punctuation instead of removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95531253608647337"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "remove_punctuation = No\n",
    "'''\n",
    "load_and_get_accuracy(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_NoStem_Punc_AboveNone_BelowNone.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this parameter, the accuracy has decreased again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must consider the continuous configuration options. The first is the hashes concatenation. Making this figure smaller decreases the file size of the obscured text and further anonymizes the data by making it more likely that two words could hash to the same value. However, that can decrease accuracy of the model. We will try values from 2 to 5 to see the impact they make on accuracy. Given our results above, we will use stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.911434246821 5.035804\n",
      "3 0.958240203186 6.695125\n",
      "4 0.95956929628 8.354446\n",
      "5 0.960103331308 10.013767\n",
      "6 0.960104040528 11.673088\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in range(2,7):\n",
    "    filename = \"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_Stem_Punc_Concat\" + str(i) + \"_AboveNone_BelowNone.csv\"\n",
    "    acc = load_and_get_accuracy(filename)\n",
    "    size = os.stat(filename).st_size\n",
    "    print(i, acc, size/1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see the relationship between the hash concatenation, the accuracy of our model, and the file size of the obscured files in MB. As we can see, the accuracy begins to plateu at concat_hashes = 5. However, this is dependent on the number of unique words in our dataset. For this example, we had 37,000 words with stemming. Therefore a reasonable rule might be to use 5 unless there are over 50,000 unique words in the dataset. (The count of unique words is printed by the obscuration script when it is finished.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will consider the lower and upper bounds for combining words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If combine_above and combine_below = Ask, the obscuration script produces these counts.\n",
    "'''\n",
    "Original_Word      Hash   Count\n",
    "58            the  Zdr9p  51817\n",
    "20             of  3MVme  30909\n",
    "17             to  Fsqeu  30297\n",
    "108             a  KqMIB  23545\n",
    "49            and  2gcdS  23357\n",
    "38             is  CWUT_  20500\n",
    "26             in  0q7Zs  19641\n",
    "13              i  dhib2  19408\n",
    "56           that  SgVfw  17890\n",
    "37             it  HeKam  14817\n",
    "82            you  5geKC  10862\n",
    "68            for  WT2-D  10738\n",
    "74             be  hO9jZ   9627\n",
    "63            not  oX23J   8957\n",
    "83            thi  RJ2Pl   8723\n",
    "0            from  b4Seg   8345\n",
    "61            are  XIAAS   8058\n",
    "4             edu  ujMnQ   7663\n",
    "95           have  fehAw   7489\n",
    "148             s  Cio4U   7449 \n",
    "\n",
    "\n",
    "25895           8mb  6Y-Qm      1\n",
    "25896        181924  NSiAu      1\n",
    "25897         21026  L_kHO      1\n",
    "25898       1000000  xy86N      1\n",
    "12989    entangleth  d2Kr_      1\n",
    "12988       warreth  btSwj      1\n",
    "3013           capp  FYM8L      1\n",
    "25902         oneof  X2Dbh      1\n",
    "3015          savel  4uCZT      1\n",
    "25906       diametr  EGceI      1\n",
    "25907         clees  w0o_V      1\n",
    "12979      incosist  7fKRI      1\n",
    "25909         heber  epTk0      1\n",
    "25910         kenit  aDfKl      1\n",
    "12978       defraud  PwuiJ      1\n",
    "25912        scenic  6lVeI      1\n",
    "12975       geisler  dyTRp      1\n",
    "25914         novak  dBGUn      1\n",
    "3017        cerullo  ZljLW      1\n",
    "35184        truest  kdnwd      1\n",
    "'''\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 0.947334454057\n",
      "10000 0.952652218446\n",
      "17000 0.952916055788\n",
      "20000 0.956640191868\n",
      "30000 0.960098362946\n",
      "None 0.96089482061\n"
     ]
    }
   ],
   "source": [
    "for i in (8000,10000,17000,20000,30000):\n",
    "    filename = \"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_Stem_NoPunc_Concat5_Above\" + str(i) +\"_Below1.csv\"\n",
    "    acc = load_and_get_accuracy(filename)\n",
    "    print(i, acc)\n",
    "print(\"None\", load_and_get_accuracy(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_Stem_NoPunc_AboveNone_BelowNone.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us the relationship between the model accuracy and what count we select to concatenate above. As we can see, we do lose accuracy when we bundle more words together. \n",
    "\n",
    "Now, turning our attention towards concatenating those below a given count. For example, if we select 2, the script will bundle words with counts of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.961963630076\n",
      "8 0.963026761961\n",
      "7 0.961962215399\n",
      "6 0.962760087739\n",
      "5 0.963291297175\n",
      "4 0.961696246635\n",
      "3 0.962228165291\n",
      "2 0.961167164888\n",
      "None 0.96089482061\n"
     ]
    }
   ],
   "source": [
    "for i in (9,8,7,6,5,4,3,2,\"None\"):\n",
    "    filename = \"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_Stem_NoPunc_Concat5_AboveNone_Below\" + str(i) + \".csv\"\n",
    "    acc = load_and_get_accuracy(filename)\n",
    "    print(i, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from these results that the trend is not quite as predictable as the bundling of the words with the highest counts. However, in general, it is best to minimize the bundling of words to not lose information. However, below a certain count, the words lose predictive power because they occur so rarely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at how some of the configuration options impact the ability of the model to predict outcomes, we now should turn our attention towards some of the difficulties of using this kind of data for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems with Obscured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this walk-through demonstrates that the anonymized text data from our obscuration process retains it predictive power for machine learning categorization. However, there are a few drawbacks. The most obvious is the totally opaque nature of the text for the model builder. This could be problematic in cases where the model is picking up on something unintended. For example, if the orignal data accidentally contained the name of the target variable, the model could predict with nearly 100% accuracy, but the model builder could not physically read the data to find the problem. To demonstrate, consider the following case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tainted_data = data_df[\"data\"] + data_df[\"target\"]\n",
    "tainted_df = pd.concat([data_df[\"target\"], tainted_data], axis=1)\n",
    "tainted_df.columns = [\"target\", \"data\"]\n",
    "tainted_df.to_csv(\"tainted_newsgroups.csv\")\n",
    "obs_tainted = pd.read_csv(\"./obscured_tainted_newsgroups/newsgroups_data_Salt=exampleString_NoCase_NoStem_NoPunc_Concat5_AboveNone_BelowNone.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data column ends with the name of the target variable, tainting the data with unwanted information. If the words are unobscured, the problem is relatively easy to see. But if it is obscured, the problem become very difficult to spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: geb@cs.pitt.edu (Gordon Banks)\n",
      "Subject: Re: \"CAN'T BREATHE\"\n",
      "Article-I.D.: pitt.19440\n",
      "Reply-To: geb@cs.pitt.edu (Gordon Banks)\n",
      "Organization: Univ. of Pittsburgh Computer Science\n",
      "Lines: 23\n",
      "\n",
      "In article <1993Mar29.204003.26952@tijc02.uucp> pjs269@tijc02.uucp (Paul Schmidt) writes:\n",
      ">I think it is important to verify all procedures with proper studies to\n",
      ">show their worthiness and risk.  I just read an interesting tidbit that \n",
      ">80% of the medical treatments are unproven and not based on scientific \n",
      ">fact.  For example, many treatments of prostate cancer are unproven and\n",
      ">the treatment may be more dangerous than the disease (according to the\n",
      ">article I read.)\n",
      "\n",
      "Where did you read this?  I don't think this is true.  I think most\n",
      "medical treatments are based on science, although it is difficult\n",
      "to prove anything with certitude.  It is true that there are some\n",
      "things that have just been found \"to work\", but we have no good\n",
      "explanation for why.  But almost everything does have a scientific\n",
      "rationale.  The most common treatment for prostate cancer is\n",
      "probably hormone therapy.  It has been \"proven\" to work.  So have\n",
      "radiation and chemotherapy.  What treatments did the article say\n",
      "are not proven?  \n",
      "\n",
      "-- \n",
      "----------------------------------------------------------------------------\n",
      "Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\n",
      "geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \n",
      "----------------------------------------------------------------------------\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "print(tainted_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b4Seg 10Khk dRaYm LYwJD ujMnQ S7fhI tVqRr aSvxX 8GOEh ZBoa5 5EKhx PR5Vb bm0jf dhib2 I48NW LYwJD fxCuf za07I Fsqeu 10Khk dRaYm LYwJD ujMnQ S7fhI tVqRr WNXx- VJwA- 3MVme a4S68 6cgjU m8ssc w1yvW vV-hc 0q7Zs bm0jf G9h6y ejl5K QCY7E A-4Hy sI42G O4oSL A-4Hy sI42G BCRN3 -xP3O 4WNbo dhib2 YkSoQ HeKam CWUT_ iZDcx Fsqeu UYWYk VjqvU pYxa4 g0NaX GX8I1 89cUm Fsqeu BMtFB xCiMp IsQ4A 2gcdS nV0dX dhib2 r0gZo gMIMP 5DMKD leHin 1JB89 SgVfw yXB70 3MVme Zdr9p dKOvp kkwzF XIAAS 6LgEE 2gcdS oX23J UVPZD o3qdl YQDPb c60Dm WT2-D dcdTZ kv3Ct kkwzF 3MVme S24xz MhFbz XIAAS 6LgEE 2gcdS Zdr9p Sdg2q ir3Cb hO9jZ aVyIC aXt6a ycYsB Zdr9p O-iFx 2AH89 Fsqeu Zdr9p bm0jf dhib2 gMIMP I7YWm ZP7Fa 5geKC gMIMP v2yHv dhib2 LOhVB 5EKhx YkSoQ v2yHv CWUT_ 8EXrH dhib2 YkSoQ jaG0a dKOvp kkwzF XIAAS UVPZD o3qdl m8ssc olbfQ HeKam CWUT_ pNYpA Fsqeu 01yJO ae0s3 g0NaX Tp8qq HeKam CWUT_ 8EXrH SgVfw vvriI XIAAS CWKnZ BO7DV SgVfw fehAw r0gZo FNqYJ F98lY Fsqeu eJZtM L3jun JLKmm fehAw 7cQw7 rFewE -x9LH WT2-D sxTUc L3jun TejJ0 OG1_V NsFSl fehAw KqMIB YQDPb mavoR Zdr9p jaG0a KVRtp Sdg2q WT2-D S24xz MhFbz CWUT_ FH-4v zVtrt KVuQe HeKam rh_Ma FNqYJ bXBo_ Fsqeu eJZtM DPJsZ fehAw WOKld 2gcdS sHJLg Hzs0j kkwzF ZP7Fa Zdr9p bm0jf 5Q2D7 XIAAS oX23J bXBo_ S7fhI tVqRr WBT5Y pdzBR CWUT_ Zdr9p rjyQD 3MVme Zdr9p RZtrC 2gcdS 10Khk gLeSy h7Mah LYwJD ujMnQ HeKam CWUT_ Etske Fsqeu z1IQx HeKam 61830 5zond LWPSa 4NIgL \n"
     ]
    }
   ],
   "source": [
    "print(obs_tainted.obscured_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991758804989\n"
     ]
    }
   ],
   "source": [
    "X = obs_tainted[\"obscured_data\"]\n",
    "y = obs_tainted[\"target\"]\n",
    "scores = cross_val_score(text_clf2, X, y, cv=10, scoring='accuracy')\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By measuring the accuracy of our same model trained on this tainted data, we can see that now the model has becomie overly accurate because the model now has access to data it should not. It is not 100% because the target names have punctuation in them, which is split into different words. So in the exapmle above \"LWPSa 4NIgL\" = \"sci.med\". And in a small percent of cases, this information can be overpowered by other indicators of classification in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this is only one example of an issue with working with completely non-human readable data. The greater takeaway is that diagnosis of problems in the data or the model becomes significantly more difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another consideration is that the obscuration severly limits the post-modeling analysis that is possible by the makers of the model. For example, we can find the word most assosciated with each category, as shown below, which can be helpful in understanding what the model is using to make its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf2.fit(X, y)\n",
    "coef = text_clf2.named_steps[\"clf\"].coef_\n",
    "vocab = text_clf2.named_steps[\"vect\"].vocabulary_\n",
    "feature_names = text_clf2.named_steps[\"vect\"].get_feature_names()\n",
    "coefs = pd.DataFrame(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf alt.atheism\n",
      "uiezi comp.graphics\n",
      "htxf3 sci.med\n",
      "3nuqu soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "for index, value in coefs.idxmax(axis=1).iteritems():\n",
    "    print(feature_names[value], twenty_train.target_names[index],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this kind of process yields little fruit with non-readable data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
