{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will replicate the textual analysis provided as a sample by scikit-learn using the fully anonymized text data processed through our text-obscuring script. At the conclusion, we will compare the results that could be derived from the cleansed text and the uncleansed text. \n",
    "\n",
    "Find the original instructions at: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our testing and training datasets have the same mapping of words to numbers, we must process them through our anonymization script together. Therefore we should load the entire dataset and split it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the data in raw form \n",
      "\n",
      "                    target                                               data\n",
      "0                 sci.med  From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
      "1  soc.religion.christian  From: swf@elsegundoca.ncr.com (Stan Friesen)\\n...\n",
      "2  soc.religion.christian  From: David.Bernard@central.sun.com (Dave Bern...\n",
      "3           comp.graphics  From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...\n",
      "4                 sci.med  From: billc@col.hp.com (Bill Claussen)\\nSubjec...\n",
      "5  soc.religion.christian  From: mauaf@csv.warwick.ac.uk (Mr P D Simmons)...\n",
      "6                 sci.med  From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady)\\n...\n",
      "7           comp.graphics  From: dfegan@lescsse.jsc.nasa.gov (Doug Egan)\\...\n",
      "8           comp.graphics  From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JPE...\n",
      "9           comp.graphics  From: chu@TorreyPinesCA.ncr.com (Patrick Chu 3...\n"
     ]
    }
   ],
   "source": [
    "#In order to use the csv obscuring python script, the data must be in CSV format. Exporting it as such:\n",
    "import pandas as pd\n",
    "data_df = pd.DataFrame(columns = [\"target\", \"data\"])\n",
    "data_df[\"target\"] = [twenty_train.target_names[i] for i in twenty_train.target]\n",
    "data_df[\"data\"] = twenty_train.data\n",
    "data_df.to_csv(\"newsgroups_train.csv\")\n",
    "print(\"A sample of the data in raw form\", \"\\n\\n\", data_df.head(10))\n",
    "\n",
    "Orig_X_train, Orig_X_test, Orig_y_train, Orig_y_test = train_test_split(data_df[\"data\"], \n",
    "                                                    data_df[\"target\"], \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3365    From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
       "563     From: edwest@gpu.utcc.utoronto.ca (Dr. Edmund ...\n",
       "Name: data, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Orig_X_train[Orig_X_train.str.contains(\"gpu\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   target                                      Cleansed_data\n",
      "0                 sci.med  38264 24044 34757 8944 36760 21565 23363 10220...\n",
      "1  soc.religion.christian  38264 18209 14880 32178 36760 21565 21621 4274...\n",
      "2  soc.religion.christian  38264 47923 24575 1921 36760 21565 35634 43508...\n",
      "3           comp.graphics  38264 4651 50050 259 16413 36760 50591 44409 6...\n",
      "4                 sci.med  38264 20181 49030 48691 36760 21565 42010 3438...\n",
      "5  soc.religion.christian  38264 16304 1643 27435 38107 23277 36760 28401...\n",
      "6                 sci.med  38264 9026 3578 51496 36760 21565 42836 24157 ...\n",
      "7           comp.graphics  38264 49775 21454 34522 36760 21565 29508 4335...\n",
      "8           comp.graphics  38264 1402 4591 21678 36760 3977 12005 7141 66...\n",
      "9           comp.graphics  38264 17553 7328 42658 25289 36760 39245 50520...\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Reimporting the data cleansed with these configurations:\n",
    "\n",
    "file_name = newsgroups_train\n",
    "output_base = newsgroups\n",
    "column_name = data\n",
    "delete_column = Yes\n",
    "index_num = 0\n",
    "\n",
    "case_sensitive = No\n",
    "stemming = No\n",
    "random_seed = 1\n",
    "remove_punctuation = Yes\n",
    "combine_above = 17000\n",
    "combine_below = 1\n",
    "'''\n",
    "anon_data = pd.read_csv(\"./cleansed_newsgroups_train/newsgroups_data_NoCase_NoStem_NoPunc_Above17000_Below1.csv\")\n",
    "print(anon_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the words have all been converted into numbers, they are stored as space seperated strings so the functions used on words will work on the numbers. \n",
    "\n",
    "The first two lines are spliting the dataset randomly into training and testing. This means that our training and testing sets will differ from the example, but is a necessary step for anonymization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 42622)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(anon_data[\"Cleansed_data\"], \n",
    "                                                    anon_data[\"target\"], \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24979"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocabulary still contains the locations of the numeralized words. Here '38264' is the number for 'From'\n",
    "count_vect.vocabulary_.get(u'38264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 42622)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 42622)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training A Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one difficulty in working with the anonymized data. Without the mapping of the original word to its number, one who is building the classification model cannot use meaningful novel data to check the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, for the sake of demonstration, it is possible to test the classifier by finding the equivalent string of numbers to \"God is love\" and \"OpenGL on the GPU is fast\" because we have the mappings exported from the cleansing process. However, we run into another difficulty. By searching the original training data, it is revealed that \"GPU\" only appears in these email addresses: \"C5u5LG.C3G@gpu.utcc.utoronto.ca\" and \"edwest@gpu.utcc.utoronto.ca\" which are cleansed into: \"c5u5lgc3ggpuutccutorontoca\" and \"edwestgpuutccutorontoca\" and assigned the numbers 13444 and 33785. Replacing \"GPU\" with either number is not exactly equivalent to classifying by the word \"GPU\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is Love' => '16572 24157 31156' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => '32837 7359 24157 GPU 24157 43731' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['16572 24157 31156', '32837 7359 24157 GPU 24157 43731']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category, original in zip(docs_new, predicted, [\"God is Love\", \"OpenGL on the GPU is fast\"]):\n",
    "    print('%r => %r => %s' % (original, doc, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nonetheless, the predictions are the same as the uncleansed data, even when leaving out the word \"GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873670212766\n"
     ]
    }
   ],
   "source": [
    "# A bit of a simpler, built-in way to get the accuracy score.\n",
    "from sklearn import metrics\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Naive Bayes, we achieved a similar classification accuracy with the anonymized strings.\n",
    "\n",
    "Now we will try the linear support vector machine using their same presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927526595745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    ">>> text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', \n",
    "                                               penalty='l2',\n",
    "                                               alpha=1e-3, \n",
    "                                               random_state=42,\n",
    "                                               max_iter=5, \n",
    "                                               tol=None)),])\n",
    "# Repeated code from above\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, our classification accuracy and report are quite similar to that achieved with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.99      0.81      0.89       339\n",
      "         comp.graphics       0.93      0.99      0.96       386\n",
      "               sci.med       0.98      0.93      0.95       388\n",
      "soc.religion.christian       0.84      0.97      0.90       391\n",
      "\n",
      "           avg / total       0.93      0.93      0.93      1504\n",
      "\n",
      "[[274   4   3  58]\n",
      " [  0 382   1   3]\n",
      " [  0  20 359   9]\n",
      " [  3   6   2 380]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same grid search with our classifier. However, we would expect that some parameters no longer behave similarly. For example, the model builder looses flexibility in using information lower than the word level on which to model the target data, such as letters or groups of punctuation, once the configuration options have been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1,1),(1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train[:400], y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.predict(['16572 24157 31156'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search has returned the same parameters as with the original data, but with a lower best score. Increasing the training size should increase the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "Time to search: 12.2 seconds\n"
     ]
    }
   ],
   "source": [
    "# Not present in original analysis. Training on the full training set (about 3000 rows)\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "print(round(gs_clf.best_score_))\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "print(\"Time to search:\", round(timeit.default_timer() - start_time, 1), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this walk-through demonstrates that the anonymized text data from our obscuration process retains it predictive power for machine learning categorization. However, there are a few drawbacks. The most obvious is the totally opaque nature of the text for the model builder. This could be problematic in cases where the model is picking up on something unintended. For example, if the orignal data accidentally contained the name of the target variable, the model could predict with 100% accuracy, but the model builder could not physically read the data to find the problem.  \n",
    "\n",
    "As mentioned before, there is also an issue with presenting novel data to the model. If the new data is not encoded with the same numbers as the original training data, the model cannot predict the outcomes. To encode data with the same numbers, in its current state, the algorithm must run the new data at the same time as the old data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
