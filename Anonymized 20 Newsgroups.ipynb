{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will replicate the textual analysis provided as a sample by scikit-learn using the fully anonymized text data processed through our text-obscuring script. At the conclusion, we will compare the results that could be derived from the cleansed text and the uncleansed text. \n",
    "\n",
    "Find the original instructions at: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that our testing and training datasets have the same mapping of words to numbers, we must process them through our anonymization script together. Therefore we should load the entire dataset and split it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the data in raw form \n",
      "\n",
      "                    target                                               data\n",
      "0                 sci.med  From: geb@cs.pitt.edu (Gordon Banks)\\nSubject:...\n",
      "1  soc.religion.christian  From: swf@elsegundoca.ncr.com (Stan Friesen)\\n...\n",
      "2  soc.religion.christian  From: David.Bernard@central.sun.com (Dave Bern...\n",
      "3           comp.graphics  From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...\n",
      "4                 sci.med  From: billc@col.hp.com (Bill Claussen)\\nSubjec...\n",
      "5  soc.religion.christian  From: mauaf@csv.warwick.ac.uk (Mr P D Simmons)...\n",
      "6                 sci.med  From: lady@uhunix.uhcc.Hawaii.Edu (Lee Lady)\\n...\n",
      "7           comp.graphics  From: dfegan@lescsse.jsc.nasa.gov (Doug Egan)\\...\n",
      "8           comp.graphics  From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JPE...\n",
      "9           comp.graphics  From: chu@TorreyPinesCA.ncr.com (Patrick Chu 3...\n"
     ]
    }
   ],
   "source": [
    "#In order to use the csv obscuring python script, the data must be in CSV format. Exporting it as such:\n",
    "import pandas as pd\n",
    "data_df = pd.DataFrame(columns = [\"target\", \"data\"])\n",
    "data_df[\"target\"] = [twenty_train.target_names[i] for i in twenty_train.target]\n",
    "data_df[\"data\"] = twenty_train.data\n",
    "data_df.to_csv(\"newsgroups.csv\")\n",
    "print(\"A sample of the data in raw form\", \"\\n\\n\", data_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   target                                      obscured_data\n",
      "0                 sci.med  b4Seg 10Khk dRaYm LYwJD ujMnQ S7fhI tVqRr aSvx...\n",
      "1  soc.religion.christian  b4Seg gMgiz v3kDg mwDQ6 fjpY2 H_Vzl BxcvF aSvx...\n",
      "2  soc.religion.christian  b4Seg VXnD4 HGFtW 0VE5D UNsQQ fjpY2 dx0ia HGFt...\n",
      "3           comp.graphics  b4Seg ympNG hnGMJ FhNWX WWr2H fjpY2 oa748 5EKh...\n",
      "4                 sci.med  b4Seg vzC1q -XaO6 7D57- fjpY2 _6ozZ _1RCs aSvx...\n",
      "5  soc.religion.christian  b4Seg nIIie ujOQs qPpKp Q2CIN 35sOC rvND4 Lvw4...\n",
      "6                 sci.med  b4Seg P2WMC jCrYJ cZV5M iT3VW ujMnQ 4v_fB P2WM...\n",
      "7           comp.graphics  b4Seg lGib2 lwttC dulL- BCuBV 1Cnnx tAD8R KVn_...\n",
      "8           comp.graphics  b4Seg -IKdR dRaYm c8m-p ujMnQ 7cmJN MGCyx aSvx...\n",
      "9           comp.graphics  b4Seg GAkWy NHVa6 mwDQ6 fjpY2 4Gs1v GAkWy -dgh...\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Reimporting the data cleansed with these configurations:\n",
    "\n",
    "file_name = newsgroups_train\n",
    "output_base = newsgroups\n",
    "column_name = data\n",
    "delete_column = Yes\n",
    "index_num = 0\n",
    "\n",
    "case_sensitive = No\n",
    "stemming = No\n",
    "random_seed = 1\n",
    "remove_punctuation = Yes\n",
    "combine_above = 17000\n",
    "combine_below = 1\n",
    "'''\n",
    "anon_data = pd.read_csv(\"./obscured_newsgroups/newsgroups_data_Salt=exampleString_NoCase_NoStem_NoPunc_AboveNone_BelowNone.csv\")\n",
    "print(anon_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the words have all been converted into numbers, they are stored as space seperated strings so the functions used on words will work on the numbers. \n",
    "\n",
    "The first two lines are spliting the dataset randomly into training and testing. This means that our training and testing sets will differ from the example, but is a necessary step for anonymization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(anon_data[\"obscured_data\"], \n",
    "                                                    anon_data[\"target\"], \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2255x38015 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 395378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary still contains the locations of the numeralized words. Here '38264' is the number for 'From'\n",
    "count_vect.vocabulary_.get(u'b4Seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2255, 38015)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training A Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one difficulty in working with the anonymized data. Without the mapping of the original word to its randomized string, one who is building the classification model cannot use meaningful novel data to check the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, for the sake of demonstration, it is possible to test the classifier by finding the equivalent string of numbers to \"God is love\" and \"OpenGL on the GPU is fast\" because we have the mappings exported from the obscuration process. However, we run into another difficulty. By searching the original training data, it is revealed that \"GPU\" only appears in these email addresses: \"C5u5LG.C3G@gpu.utcc.utoronto.ca\" and \"edwest@gpu.utcc.utoronto.ca\" which are turned into seperate words: \"c5u5lg c3g gpu utcc utoronto ca\" and \"edwest gpu utcc utoronto ca\". Then \"gpu\" is converted into the string \"Bb4UV\". So we can see that using the string \"gpu\" is not matching something meaningful in our sample data. However, this insight is only possible with non-obscured data, and the lack of it could lead to a flawed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is Love' => 'uYWvU CWUT_ cr2_s' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => 'fGKDi o3qdl Zdr9p Bb4UV CWUT_ HkaPm' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['uYWvU CWUT_ cr2_s', 'fGKDi o3qdl Zdr9p Bb4UV CWUT_ HkaPm']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category, original in zip(docs_new, predicted, [\"God is Love\", \"OpenGL on the GPU is fast\"]):\n",
    "    print('%r => %r => %s' % (original, doc, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The predictions are the same as the uncleansed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894946808511\n"
     ]
    }
   ],
   "source": [
    "# A bit of a simpler, built-in way to get the accuracy score.\n",
    "from sklearn import metrics\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that, using the Naive Bayes, we achieved a similar classification accuracy to their 83.4% with the our obscured strings. Our accuracy is not the exact same for a number of reasons. First, the original walkthrough used predivided training and testing data. We split our set using the scikit learn's function. Also, we made two selections in obscuring our data: to striped punctuation and run as case insensitive.\n",
    "\n",
    "Now we will try the linear support vector machine using their same presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948803191489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    ">>> text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', \n",
    "                                               penalty='l2',\n",
    "                                               alpha=1e-3, \n",
    "                                               random_state=42,\n",
    "                                               max_iter=5, \n",
    "                                               tol=None)),])\n",
    "# Repeated code from above\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, our classification accuracy above and report are quite similar to their 91.2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.99      0.91      0.95       339\n",
      "         comp.graphics       0.90      0.99      0.95       386\n",
      "               sci.med       0.98      0.93      0.95       388\n",
      "soc.religion.christian       0.94      0.96      0.95       391\n",
      "\n",
      "           avg / total       0.95      0.95      0.95      1504\n",
      "\n",
      "[[310   3   6  20]\n",
      " [  0 383   1   2]\n",
      " [  0  26 359   3]\n",
      " [  3  12   1 375]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same grid search with our classifier. However, we would expect that some parameters no longer behave similarly. For example, the model builder looses flexibility in using information lower than the word level on which to model the target data, such as letters or groups of punctuation, once the configuration options have been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1,1),(1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train[:400], y_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.predict(['16572 24157 31156'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8975\n",
      "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search has returned the same parameters as with the original data with a very similar accuracy score to their 90.0%.\n",
    "\n",
    "This concludes the example that was provided by scikit learn. Now, we will look at some of the configuration options for the obscuration script and how they effect accuracy in interpretibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring The Obscuration Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this walk-through demonstrates that the anonymized text data from our obscuration process retains it predictive power for machine learning categorization. However, there are a few drawbacks. The most obvious is the totally opaque nature of the text for the model builder. This could be problematic in cases where the model is picking up on something unintended. For example, if the orignal data accidentally contained the name of the target variable, the model could predict with 100% accuracy, but the model builder could not physically read the data to find the problem.  \n",
    "\n",
    "As mentioned before, there is also an issue with presenting novel data to the model. If the new data is not encoded with the same numbers as the original training data, the model cannot predict the outcomes. To encode data with the same numbers, in its current state, the algorithm must run the new data at the same time as the old data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
