[Data]
# Specify the name of the CSV file without its extension:
file_name = newsgroups_train

# Specify the base output name for the cleansed file:
output_base = newsgroups

# Specify the name of the column to cleanse
column_name = data

# Would you like to delete that column in the output file (Yes/No)?
delete_column = Yes

#The number (starting with 0) of the index column. Write None is none exists
index_num = 0


[Processing]
# Would you like to run as case sensitive? (Yes, No, or Both)
case_sensitive = No

# Would you like to use stemming, which requires importing NLTK? (Yes, No, or Both)
stemming = No

# Would you like to remove punctuation? (Yes, No, or Both)
# Selecting 'No' will treat punctuation as word themselves.
remove_punctuation = Yes

# Please enter a string to be used as a salt for hashing. 
salt_string = exampleString

# How many characters to which you would like to concatenate the hashes? (Int or None)
concat_hashes = 5

# Combine words with counts above (an integer, or, if you want to be shown the counts and then input a number in the terminal, write 'Ask'. Write 'None' to not combine)
combine_above = None

# Combine words with counts below (an integer, 'Ask', or 'None')
combine_below = None

# Please type in custom stop words separated by space. Will be case sensitive if selected above. 
stop_words = a an and are as at be by for from has he in is it its of on that the to was were will with

# If using the script to encode new data in the same way as previous encodings, fill the variables below with the exported stop_words_above and stop_words_below from the first encoding. Then, set the combine_above and combine below to 'None'. Otherwise, leave blank.
stop_above_words = 
stop_below_words = 



